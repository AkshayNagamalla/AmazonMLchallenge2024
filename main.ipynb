{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm Alchemists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import constants\n",
    "import spacy\n",
    "from typing import Dict, Set, Tuple, Optional, List, Any"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_FOLDER = '../dataset/'\n",
    "train = pd.read_csv(os.path.join(DATASET_FOLDER, 'train.csv'))\n",
    "test = pd.read_csv(os.path.join(DATASET_FOLDER, 'test.csv'))\n",
    "sample_test = pd.read_csv(os.path.join(DATASET_FOLDER, 'sample_test.csv'))\n",
    "sample_test_out = pd.read_csv(os.path.join(DATASET_FOLDER, 'sample_test_out.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_test.entity_name.head(),sample_test_out.prediction.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import download_images\n",
    "download_images(sample_test['image_link'], '../images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(os.listdir('../images_test'))>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -rf ./images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting Text from images using Paddle OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary libraries\n",
    "import cv2\n",
    "import csv\n",
    "from paddleocr import PaddleOCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the OCR model\n",
    "ocr = PaddleOCR(use_angle_cls=True, lang='en') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory containing images and the output CSV file path\n",
    "image_directory = '../images_test'\n",
    "output_csv = '../dataset/ocr_results_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create or open the CSV file to save the results\n",
    "with open(output_csv, mode='a', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"image_link\", \"extracted_text\"])  # Header row\n",
    "\n",
    "    # Loop through each image in the directory\n",
    "    for image_name in os.listdir(image_directory):\n",
    "        if image_name.endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff')):  # Filter for image files\n",
    "            image_path = os.path.join(image_directory, image_name)\n",
    "\n",
    "            # Read the image\n",
    "            img = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "            # Perform OCR on the image\n",
    "            try:\n",
    "                res = ocr.ocr(img, cls=True)\n",
    "                if res[0] == None :\n",
    "                    writer.writerow([image_path,None])\n",
    "                    continue\n",
    "                # Extract all text from the image\n",
    "                extracted_text = \"\"\n",
    "                for line in res:\n",
    "                    for word_info in line:\n",
    "                        extracted_text += word_info[-1][0] + \" \"  # Concatenate all the words\n",
    "\n",
    "                # Write the image path and extracted text to the CSV file\n",
    "                writer.writerow([image_path, extracted_text.strip()])\n",
    "            except:\n",
    "                print(image_path)\n",
    "                continue\n",
    "print(\"OCR completed and results saved to\", output_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading extracted text and test.csv\n",
    "\n",
    "df = pd.read_csv(\"../dataset/test.csv\")\n",
    "ou = pd.read_csv(\"../dataset/ocr_results_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing and mapping the extracted data to dataframe\n",
    "\n",
    "df['image_link'] = df['image_link'].apply(lambda x: x.split('/')[-1])\n",
    "\n",
    "df.drop(columns=['group_id'],inplace=True)\n",
    "\n",
    "ou['image_link'] = ou['image_link'].apply(lambda x: x.split('/')[-1])\n",
    "\n",
    "ou['image_link'] = ou['image_link'].apply(lambda x: x.split('\\\\')[-1])\n",
    "\n",
    "ou = ou.merge(df, on=['image_link'], how='right')\n",
    "\n",
    "ou.drop(columns=['image_link'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Named Entity Recognition (NER) model is built for each entity name using the spaCy framework, therefore creating total of 8 models\n",
    "# For training script refer multiprocess_df.py\n",
    "# Loading all NER models\n",
    "\n",
    "width = spacy.load(\"../models/output__width/model-best/\")\n",
    "\n",
    "depth = spacy.load(\"../models/output__depth/model-best/\")\n",
    "\n",
    "height = spacy.load(\"../models/output__height/model-best/\")\n",
    "\n",
    "max_weight = spacy.load(\"../models/output__maximum_weight_recommendation/model-best/\")\n",
    "\n",
    "wattage = spacy.load(\"../models/output__wattage/model-best/\")\n",
    "\n",
    "voltage = spacy.load(\"../models/output__voltage/model-best/\")\n",
    "\n",
    "item_volume = spacy.load(\"../models/output__item_volume/model-best/\")\n",
    "\n",
    "item_weight = spacy.load(\"../models/output__item_weight/model-best/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backup method for entity value recognition is Ruled-Based Recognition\n",
    "# The EntityValueExtractor class contains methods for RBR\n",
    "\n",
    "class EntityValueExtractor:\n",
    "    def __init__(self, entity_unit_map: Dict[str, Set[str]], default_units: Dict[str, str], unit_mapping: Dict[str, str]):\n",
    "        self.entity_unit_map = entity_unit_map\n",
    "        self.default_units = default_units\n",
    "        self.unit_mapping = unit_mapping\n",
    "        self.allowed_units = {unit for units in entity_unit_map.values() for unit in units}\n",
    "        self.reverse_unit_mapping = {v: k for k, v in unit_mapping.items()}\n",
    "\n",
    "    def preprocess_text(self, text: str) -> str:\n",
    "        if not isinstance(text, str):\n",
    "            return \"\"\n",
    "        text = text.replace('\"', ' inch ')\n",
    "        # text = text.replace('\\'', ' foot ')\n",
    "        text = re.sub(r'(\\d+),(?=0+[^\\d])', r'\\1', text)\n",
    "        text = re.sub(r'(\\d+),(\\d+)', r'\\1.\\2', text)\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'(\\d+)\\s*0z', r'\\1 oz', text)\n",
    "        # Handle prefix\n",
    "        text = re.sub(r'wt\\.(\\d+)([a-zA-Z]+)', r'\\1 \\2', text)\n",
    "        text = re.sub(r'max\\.(\\d+)([a-zA-Z]+)', r'\\1 \\2', text)\n",
    "        text = re.sub(r'qty\\.(\\d+)([a-zA-Z]+)', r'\\1 \\2', text)\n",
    "        text = re.sub(r'qt\\.(\\d+)([a-zA-Z]+)', r'\\1 \\2', text)\n",
    "        # Handle hyphenated number-unit pairs\n",
    "        text = re.sub(r'(\\d+)-([a-zA-Z]+)', r'\\1 \\2', text)\n",
    "        text = re.sub(r'([a-zA-Z]+)-(\\d+)', r'\\1 \\2', text)\n",
    "        # Separate numbers and units when directly attached\n",
    "        text = re.sub(r'(\\d+)([a-zA-Z]+)', r'\\1 \\2', text)\n",
    "        return text\n",
    "\n",
    "    def extract_values_from_text(self, text: str) -> List[Tuple[float, str]]:\n",
    "        text = self.preprocess_text(text)\n",
    "        # Updated pattern to handle 'WT.' cases, hyphenated pairs, and general number-unit pairs\n",
    "        pattern = r'(?:wt\\.)?([-+]?\\d*\\.?\\d+)\\s*-?\\s*([a-zA-Z]+(?:-[a-zA-Z]+)?)'\n",
    "        matches = re.findall(pattern, text)\n",
    "        return [(float(value), self.normalize_unit(unit)) for value, unit in matches]\n",
    "\n",
    "    def normalize_unit(self, unit: str) -> str:\n",
    "        unit = unit.lower().rstrip('s')\n",
    "        return self.unit_mapping.get(unit, unit)\n",
    "\n",
    "    def find_unit_in_text(self, text: str, entity: str) -> Optional[str]:\n",
    "        text = self.preprocess_text(text)\n",
    "        for unit in self.entity_unit_map.get(entity, set()):\n",
    "            if unit.lower() in text or any(abbr.lower() in text for abbr in self.reverse_unit_mapping if self.reverse_unit_mapping[abbr] == unit):\n",
    "                return unit\n",
    "        return None\n",
    "\n",
    "    def map_value_to_entity(self, value: float, unit: str, entity: str) -> Optional[Tuple[float, str]]:\n",
    "        normalized_unit = self.normalize_unit(unit)\n",
    "        if normalized_unit in self.entity_unit_map.get(entity, set()):\n",
    "            return (value, normalized_unit)\n",
    "        return None\n",
    "\n",
    "    def format_float(self, value: float) -> str:\n",
    "        if value == 0:\n",
    "            return \"0.0\"\n",
    "        abs_value = abs(value)\n",
    "        if abs_value < 0.01 or abs_value >= 1e7:\n",
    "            return f\"{abs_value:.6f}\".rstrip('0').rstrip('.')\n",
    "        else:\n",
    "            return f\"{abs_value:.2f}\".rstrip('0').rstrip('.')\n",
    "\n",
    "    def extract(self, text: Any, entity: str) -> Optional[str]:\n",
    "        if not isinstance(text, str):\n",
    "            text = str(text)\n",
    "        extracted_values = self.extract_values_from_text(text)\n",
    "        matching_values = []\n",
    "\n",
    "        # Original logic for other entities\n",
    "        for value, unit in extracted_values:\n",
    "            result = self.map_value_to_entity(value, unit, entity)\n",
    "            if result:\n",
    "                matching_values.append(result)\n",
    "\n",
    "        if matching_values:\n",
    "            largest_value = max(matching_values, key=lambda x: x[0])\n",
    "            return f\"{self.format_float(largest_value[0])} {largest_value[1]}\"\n",
    "\n",
    "        found_unit = self.find_unit_in_text(text, entity)\n",
    "        if found_unit:\n",
    "            values = [value for value, _ in extracted_values]\n",
    "            if values:\n",
    "                return f\"{self.format_float(max(values))} {found_unit}\"\n",
    "\n",
    "        default_unit = self.default_units.get(entity)\n",
    "        if default_unit and extracted_values:\n",
    "            values = [value for value, _ in extracted_values]\n",
    "            return f\"{self.format_float(max(values))} {default_unit}\"\n",
    "\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "\n",
    "default_units = {\n",
    "    'height': 'centimetre',\n",
    "    'width': 'centimetre',\n",
    "    'depth': 'centimetre',\n",
    "    'length': 'centimetre',\n",
    "    'item_weight': 'gram',\n",
    "    'maximum_weight_recommendation': 'gram',\n",
    "    'voltage': 'volt',\n",
    "    'wattage': 'watt',\n",
    "    'item_volume': 'millilitre'\n",
    "}\n",
    "\n",
    "unit_mapping = {\n",
    "    'in': 'inch', '\"': 'inch', 'inch': 'inch', 'inches': 'inch', 'foot': 'foot', 'ft': 'foot',\n",
    "    'cm': 'centimetre', 'm': 'metre', 'mm': 'millimetre', \n",
    "    'yard': 'yard', 'yd': 'yard',\n",
    "    'g': 'gram', 'kg': 'kilogram', \n",
    "    'mg': 'milligram', 'lb': 'pound', 'lbs': 'pound', 'oz': 'ounce', \n",
    "    'l': 'litre', 'ml': 'millilitre', 'cl': 'centilitre',\n",
    "    'v': 'volt', 'kv': 'kilovolt', 'mv': 'millivolt',\n",
    "    'w': 'watt', 'kw': 'kilowatt',\n",
    "    'fl oz': 'fluid ounce', 'gal': 'gallon', 'qt': 'quart', 'pt': 'pint',\n",
    "    'cu ft': 'cubic foot', 'cu in': 'cubic inch',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating EntityValueExtractor class instance\n",
    "extractor = EntityValueExtractor(constants.entity_unit_map, default_units, unit_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing of OCR extracted text before feeding it to the model\n",
    "\n",
    "def preprocess_text(text):\n",
    "    unit_replacements = {\n",
    "        # Length and dimension units\n",
    "        r'(\\d+(\\.\\d+)?)\\s*\\'' : r' \\1 foot ',  # Single quote for feet\n",
    "        r'(\\d+(\\.\\d+)?)\\s*\\\"' : r' \\1 inch ',  # Double quote for inches\n",
    "        r'(\\d+(\\.\\d+)?)\\s*(in|In|\"|\\'|inch|Inch|inchs|inches|Inches)\\b': r' \\1 inch ',\n",
    "        r'(\\d+(\\.\\d+)?)\\s*(ft|FT|feet|Feet|foot|Foot)\\b': r'\\1 foot ',\n",
    "        r'(\\d+(\\.\\d+)?)\\s*(cm|CM|centimeters|Centimeters|centimetre|Centimetre)\\b': r' \\1 centimetre ',\n",
    "        r'(\\d+(\\.\\d+)?)\\s*(m|M|metre|Metre|meters|Meters)\\b': r' \\1 metre ',\n",
    "        r'(\\d+(\\.\\d+)?)\\s*(mm|MM|millimeters|Millimeters|millimetre|Millimetre)\\b': r' \\1 millimetre ',\n",
    "        r'(\\d+(\\.\\d+)?)\\s*(yard|Yard|yards|Yards)\\b': r'\\1 yard ',\n",
    "        # Weight units\n",
    "        r'(\\d+(\\.\\d+)?)\\s*(g|gr|G|grams|Grams|gram|Gram)\\b': r' \\1 gram ',\n",
    "        r'(\\d+(\\.\\d+)?)\\s*(kg|KG|kilograms|Kilograms|kilogram|Kilogram)\\b': r' \\1 kilogram ',\n",
    "        r'(\\d+(\\.\\d+)?)\\s*(mg|MG|milligrams|Milligrams|milligram|Milligram)\\b': r' \\1 milligram ',\n",
    "        r'(\\d+(\\.\\d+)?)\\s*(lb|1b|1bs|LB|lbs|LBS|pounds|Pounds|pound|Pound)\\b': r' \\1 pound ',\n",
    "        r'(\\d+(\\.\\d+)?)\\s*(oz|OZ|0z|ounces|Ounces|ounce|Ounce)\\b': r' \\1 ounce ',\n",
    "        r'(\\d+(\\.\\d+)?)\\s*(ton|Ton|tons|Tons)\\b': r' \\1 ton ',\n",
    "        # Volume units\n",
    "        r'(\\d+(\\.\\d+)?)\\s*(l|L|liters|Liters|litres|Litres|litre|Litre)\\b': r' \\1 litre ',\n",
    "        r'(\\d+(\\.\\d+)?)\\s*(ml|ML|milliliters|Milliliters|millilitres|Millilitres|millilitre|Millilitre)\\b': r' \\1 millilitre ',\n",
    "        r'(\\d+(\\.\\d+)?)\\s*(cl|CL|centiliters|Centiliters|centilitre|Centilitre)\\b': r' \\1 centilitre ',\n",
    "        r'(\\d+(\\.\\d+)?)\\s*(dl|DL|deciliters|Deciliters|decilitre|Decilitre)\\b': r' \\1 decilitre ',\n",
    "        r'(\\d+(\\.\\d+)?)\\s*(microlitre|Microlitre|microliters|Microliters|µL|uL)\\b': r' \\1 microlitre ',\n",
    "        r'(\\d+(\\.\\d+)?)\\s*(pint|Pint|pints|Pints)\\b': r' \\1 pint ',\n",
    "        r'(\\d+(\\.\\d+)?)\\s*(quart|Quart|quarts|Quarts)\\b': r' \\1 quart ',\n",
    "        r'(\\d+(\\.\\d+)?)\\s*(cup|Cup|cups|Cups)\\b': r' \\1 cup ',\n",
    "        r'(\\d+(\\.\\d+)?)\\s*(gallon|Gallon|gallons|Gallons)\\b': r' \\1 gallon ',\n",
    "        r'(\\d+(\\.\\d+)?)\\s*(imperial gallon|Imperial Gallon|imperial gallons|Imperial Gallons)\\b': r' \\1 imperial gallon ',\n",
    "        r'(\\d+(\\.\\d+)?)\\s*(cubic inch|Cubic Inch|cubic inches|Cubic Inches)\\b': r' \\1 cubic inch ',\n",
    "        r'(\\d+(\\.\\d+)?)\\s*(cubic foot|Cubic Foot|cubic feet|Cubic Feet)\\b': r' \\1 cubic foot ',\n",
    "        r'(\\d+(\\.\\d+)?)\\s*(fl oz|floz|FL OZ|fluid ounce|Fluid Ounce|fluid ounces|Fluid Ounces)\\b': r' \\1 fluid ounce ',\n",
    "        # Voltage units\n",
    "        r'(\\d+(\\.\\d+)?)\\s*(volt|Volt|volts|Volts|v|V)\\b': r' \\1 volt ',\n",
    "        r'(\\d+(\\.\\d+)?)\\s*(kilovolt|Kilovolt|kV|KV)\\b': r' \\1 kilovolt ',\n",
    "        r'(\\d+(\\.\\d+)?)\\s*(millivolt|Millivolt|mV|MV)\\b': r' \\1 millivolt ',\n",
    "        # Power units\n",
    "        r'(\\d+(\\.\\d+)?)\\s*(watt|Watt|watts|Watts|w|W)\\b': r' \\1 watt ',\n",
    "        r'(\\d+(\\.\\d+)?)\\s*(kilowatt|Kilowatt|kW|KW)\\b': r' \\1 kilowatt '\n",
    "    }\n",
    "    # Replace unit misspellings and handle units attached to numbers\n",
    "    for pattern, replacement in unit_replacements.items():\n",
    "        text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing the model generated outputs and Rule-Based Recognition outputs\n",
    "import utils\n",
    "def parse_string(s):\n",
    "    s_stripped = \"\" if s==None or str(s)=='nan' else s.strip()\n",
    "    if s_stripped == \"\":\n",
    "        return \"\"\n",
    "    pattern = re.compile(r'^-?\\d+(\\.\\d+)?\\s+[a-zA-Z\\s]+$')\n",
    "    if not pattern.match(s_stripped):\n",
    "        return \"\"\n",
    "    parts = s_stripped.split(maxsplit=1)\n",
    "    number = float(parts[0])\n",
    "    unit = utils.common_mistake(parts[1])\n",
    "    if unit not in constants.allowed_units:\n",
    "        return \"\"\n",
    "    return s\n",
    "\n",
    "def predict_entity(text, entity_type, counter):\n",
    "    # Dictionary to map entity types to their respective models\n",
    "    model_map = {\n",
    "        \"width\": width,\n",
    "        \"height\": height,\n",
    "        \"maximum_weight_recommendation\": max_weight,\n",
    "        \"wattage\": wattage,\n",
    "        \"voltage\": voltage,\n",
    "        \"item_volume\": item_volume,\n",
    "        \"item_weight\": item_weight,\n",
    "        \"depth\": depth\n",
    "    }\n",
    "    \n",
    "    if type(text) != type(\"s\"):\n",
    "        return \"\"\n",
    "    # Preprocess the text\n",
    "    preprocessed_text = preprocess_text(text)\n",
    "    \n",
    "    if entity_type == 'wattage':\n",
    "        counter[0]+=1\n",
    "        return extractor.extract(text,entity_type)\n",
    "    # Get the appropriate model and make the prediction\n",
    "    model = model_map[entity_type]\n",
    "    doc = model(preprocessed_text)\n",
    "    \n",
    "    # sanity Check\n",
    "    if len(doc.ents)!=0:\n",
    "        s = str(doc.ents[0])\n",
    "        if parse_string(s)!=\"\":\n",
    "            return s\n",
    "    return extractor.extract(text,entity_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131187/131187 [15:09<00:00, 144.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Generating entity values for test dataset\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "def safe_predict_entity(row):\n",
    "    try:\n",
    "        return predict_entity(row['extracted_text'], row['entity_name'],counter)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing row: {row}\")\n",
    "        print(f\"Error message: {str(e)}\")\n",
    "        return \"Error\"\n",
    "\n",
    "# Use progress_apply instead of apply\n",
    "counter = []\n",
    "counter.append(0)\n",
    "ou['prediction'] = ou.progress_apply(safe_predict_entity, axis=1)\n",
    "print(counter[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>extracted_text</th>\n",
       "      <th>index</th>\n",
       "      <th>entity_name</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.63in 6.68cm 91.44cm - 199.39cm 36in - 78in</td>\n",
       "      <td>0</td>\n",
       "      <td>height</td>\n",
       "      <td>2.63 inch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Size Width Length One Size 42cm/16.54\" 200cm/7...</td>\n",
       "      <td>1</td>\n",
       "      <td>width</td>\n",
       "      <td>200 centimetre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Size Width Length One Size 42cm/16.54\" 200cm/7...</td>\n",
       "      <td>2</td>\n",
       "      <td>height</td>\n",
       "      <td>200 centimetre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Size Width Length One Size 42cm/16.54\" 200cm/7...</td>\n",
       "      <td>3</td>\n",
       "      <td>depth</td>\n",
       "      <td>200 centimetre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Size Width Length One Size 10.50cm/4.13\" 90cm/...</td>\n",
       "      <td>4</td>\n",
       "      <td>depth</td>\n",
       "      <td>90 centimetre</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      extracted_text  index entity_name  \\\n",
       "0       2.63in 6.68cm 91.44cm - 199.39cm 36in - 78in      0      height   \n",
       "1  Size Width Length One Size 42cm/16.54\" 200cm/7...      1       width   \n",
       "2  Size Width Length One Size 42cm/16.54\" 200cm/7...      2      height   \n",
       "3  Size Width Length One Size 42cm/16.54\" 200cm/7...      3       depth   \n",
       "4  Size Width Length One Size 10.50cm/4.13\" 90cm/...      4       depth   \n",
       "\n",
       "       prediction  \n",
       "0       2.63 inch  \n",
       "1  200 centimetre  \n",
       "2  200 centimetre  \n",
       "3  200 centimetre  \n",
       "4   90 centimetre  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ou.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the output csv\n",
    "ou.drop(columns=['extracted_text','entity_name'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the output to sample_output.csv\n",
    "ou.to_csv('output.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Sanity check using src/sanity.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing successfull for file: test_output_5_6.csv\n"
     ]
    }
   ],
   "source": [
    "!python sanity.py --test_filename ../dataset/test.csv --output_filename \"output.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
